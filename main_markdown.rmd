
---
title: "IML Term project"
author: "Julia Palorinne, Pyry Silomaa, Sara Sippola"
output: pdf_document
date: '`r format(Sys.Date(), "%d.%m.%Y")`'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(kableExtra)
```

```{r load data}
npf <- read.csv("npf_train.csv")
```

```{r preprocess data}

# Muokataan dataa.

# Luodaan class2, 0 = nonevent, 1 = event
npf$class2 <- ifelse(npf$class4 == "nonevent", 0, 1)

# Tehdään päivämäärästä rivitunniste
rownames(npf) <- npf[, "date"]

# Poistetaan sarakkeet id, date, class4, partlybad
npf <- npf[, -(1:4)]

# Puolitetaan training data jotta saadaan realistinen testausdata
set.seed(42)
idx <- sample(nrow(npf), nrow(npf)/2)
npf_train <- npf[idx, ]
npf_test <- npf[-idx, ]
```


```{r functions}

# mean squared error
mse <- function(yhat, y) sqrt(mean((y - yhat)**2))

## accuracy
accuracy <- function(pred, y) mean(ifelse(pred >= 0.5, 1, 0) == y)

## perplexity. Pakotetaan todennäköisyydet tässä välille [0.995, 0.005]
perplexity <- function(pred, y){
  pred <- ifelse(pred != 0 & pred != 1, pred, ifelse(pred == 0, 0.005, 0.995 ))
  exp(-mean(log(ifelse(y == 1, pred, 1 - pred)))) }

# cross-validate
# split n items into k folds of roughly equal size
kpart <- function(n, k) {
    rep_len(1:k, length.out = n)
}

# Find cross-validation predictions
cv <- function(
               formula, # Formula specifying which variables to use
               data, # Dataset
               model = lm, # Type of model to train (as a function)
               n = nrow(data), # number of rows in the data matrix
               k = min(n, 10), # number of cross-validation folds
               split = kpart(n, k), # the split of n data items into k folds
               ## function to train a model on data
               train = function(data) model(formula, data = data),
               ## function to make predictions on the trained model
               pred = function(model, data) predict(model, newdata = data, type = "raw")[,2]) {
    yhat <- NULL
    for (i in 1:k) {
        ## go through all folds, train on other folds, and make a prediction
        mod <- train(data[split != i, ])
        if (is.null(yhat)) {
            ## initialise yhat to something of correct data type,
            yhat <- pred(mod, data)
        } else {
            yhat[split == i] <- pred(mod, data[split == i, ])
        }
    }
    yhat # finally, output cross-validation predictions
}

# loocv <- function(
#                formula, # Formula specifying which variables to use
#                data, # Dataset
#                model = lm, # Type of model to train (as a function)
#                ## function to train a model on data
#                train = function(data) model(formula, data = data),
#                ## function to make predictions on the trained model
#                pred = function(model, data) predict(model, newdata = data, type = "raw")[,2]) {
#     yhat <- NULL
#     for (i in 1:nrow(data)) {
#         ## go through all stations, train on other stations, and make a prediction
#         mod <- train(data[-i, ])
#         if (is.null(yhat)) {
#             ## initialise yhat to something of correct data type,
#             yhat <- pred(mod, data)
#         } else {
#             yhat[i] <- pred(mod, data[i, ])
#         }
#     }
#     yhat # finally, output cross-validation predictions
# }

```

# Classifiers

## Testing classifiers as they are

### Naive Bayes

```{r naive bayes}

library(e1071)

nb.fit <- naiveBayes(class2 ~ . , data = npf_train, laplace = 1)
nb.pred.cv <- cv(class2 ~ ., npf, naiveBayes) # Hidas prosessi, tehdään siksi vaan kerran

nb_acc <- data.frame(train = accuracy(predict(nb.fit, newdata = npf_train, type = "raw")[,2], npf_train$class2),
                     test = accuracy(predict(nb.fit, newdata = npf_test, type = "raw")[,2], npf_test$class2),
                     CV = accuracy(nb.pred.cv, npf$class2))

# Kaikkiin tulee Inf
nb_perp <- data.frame(train = perplexity(predict(nb.fit, newdata = npf_train, type = "raw")[,2], npf_train$class2),
                      test = perplexity(predict(nb.fit, newdata = npf_test, type = "raw")[,2], npf_test$class2),
                      CV = perplexity(nb.pred.cv, npf$class2))

kable(cbind(nb_acc,
            nb_perp)) %>%
  add_header_above(c("Accuracy" = 3, "Perplexity" = 3))

```

### LDA
```{r lda}

library(MASS)

lda.fit <- lda(class2 ~ . , data = npf_train)

# Cross-validation parametrit
n = nrow(npf) # number of rows in the data matrix
k = min(n, 10) # number of cross-validation folds
split = kpart(n, k) # the split of n data items into k folds
lda.pred.cv <- rep(0,n)

# cv
for (i in 1:k) {
  ## go through all folds, train on other folds, and make a prediction
  mod <- lda(class2 ~ ., npf[split != i, ])
  lda.pred.cv[split == i] <- predict(mod, npf[split == i, ])$posterior[,2]
}


lda_acc <- data.frame(train = accuracy(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = accuracy(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = accuracy(lda.pred.cv, npf$class2))

lda_perp <- data.frame(train = perplexity(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = perplexity(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = perplexity(lda.pred.cv, npf$class2))

kable(cbind(lda_acc,
            lda_perp)) %>%
  add_header_above(c("Accuracy" = 3, "Perplexity" = 3))


```

### QDA
```{r qda}

library(MASS)

qda.fit <- qda(class2 ~ . , data = npf_train)

# Cross-validation parametrit
n = nrow(npf) # number of rows in the data matrix
k = min(n, 10) # number of cross-validation folds
split = kpart(n, k) # the split of n data items into k folds
qda.pred.cv <- rep(0,n)

# cv
for (i in 1:k) {
  ## go through all folds, train on other folds, and make a prediction
  mod <- qda(class2 ~ ., npf[split != i, ])
  qda.pred.cv[split == i] <- predict(mod, npf[split == i, ])$posterior[,2]
}

qda_acc <- data.frame(train = accuracy(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = accuracy(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = accuracy(qda.pred.cv, npf$class2))

# Taas Inf :(
qda_perp <- data.frame(train = perplexity(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = perplexity(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = perplexity(qda.pred.cv, npf$class2))

kable(cbind(qda_acc,
            qda_perp)) %>%
  add_header_above(c("Accuracy" = 3, "Perplexity" = 3))


```

# Preprocessing data

## Correlation

Looking at the correlation matrix as it was presented in the solutions to Exercise set 1, it is clear that the measurements of the same thing at different heights correlate, as do some of the radiation-related parameters.

```{r correlation, message=FALSE}
library(corrplot)

# Calculate the correlation matrix
cm <- cor(npf[, endsWith(colnames(npf), ".mean")])
# Remove .mean from column and row names.
colnames(cm) <- rownames(cm) <- sapply(colnames(cm), function(s) gsub(".mean", "", s))
# Order variables by 1st principal component (PCA later in the course!)
corrplot(cm, order = "FPC", tl.cex = 0.5, tl.col = "black")

```


### Correlation between measurements at different heights

Looking at the numeric values, we see that the measurements at different heights have strong positive correlation. Because of this, it is 

```{r correlation, message=FALSE}

# Korrelaatiomatriisi
cm <- cor(npf[, endsWith(colnames(npf), ".mean")])

# Remove .mean from column and row names.
colnames(cm) <- rownames(cm) <- sapply(colnames(cm), function(s) gsub(".mean", "", s))

# Muuttujakohtaiset korrelaatiot (kun enemmän kuin yksi muuttuja, jolla sama alkuosa)
kable(cm[startsWith(colnames(cm), "CO2"), startsWith(colnames(cm), "CO2")],
      caption = "Correlation (CO2)") %>%
  kable_styling()

kable(cm[startsWith(colnames(cm), "H2O"), startsWith(colnames(cm), "H2O")],
      caption = "Correlation (H20)") %>%
  kable_styling()

kable(cm[startsWith(colnames(cm), "NO") & !startsWith(colnames(cm), "NOx"), startsWith(colnames(cm), "NO") & !startsWith(colnames(cm), "NOx")],
      caption = "Correlation (NO)") %>%
  kable_styling()

kable(cm[startsWith(colnames(cm), "NOx"), startsWith(colnames(cm), "NOx")],
      caption = "Correlation (NOx)") %>%
  kable_styling()

kable(cm[startsWith(colnames(cm), "O3"), startsWith(colnames(cm), "O3")],
      caption = "Correlation (O3)") %>%
  kable_styling()

kable(cm[startsWith(colnames(cm), "RHIRGA"), startsWith(colnames(cm), "RHIRGA")],
      caption = "Correlation (RHIRGA)") %>%
  kable_styling()

kable(cm[startsWith(colnames(cm), "T"), startsWith(colnames(cm), "T")],
      caption = "Correlation (T)") %>%
  kable_styling()

```


### Measurement heights

```{r muuttujakorkeudet, message=FALSE}


# Tunnistetaan, miltä korkeudelta on otettu mitäkin mittauksia
# Sarakkeet
cols <- unname(sapply(colnames(npf[endsWith(colnames(npf), ".mean")]), function(s) gsub(".mean", "", s)))

# Taulukko muuttujista eri korkeuksissa (vain niille muuttujille, joista mittauksia eri korkeuksissa)
kable(data.frame(m.42 = c(sort(cols[endsWith(cols, "42")])[1:6], NA, sort(cols[endsWith(cols, "42")])[7]),
                                m.84 = c(NA, sort(cols[endsWith(cols, "84")])[1:5], NA, sort(cols[endsWith(cols, "84")])[6]),
                                m.168 = c(sort(cols[endsWith(cols, "168")])),
                                m.336 = c(sort(cols[endsWith(cols, "336")])[1:4], NA, sort(cols[endsWith(cols, "336")])[5], NA, NA),
                                m.504 = c(sort(cols[endsWith(cols, "504")])[1:6], NA, sort(cols[endsWith(cols, "504")])[7]),
                                m.672 = c(NA, NA, sort(cols[endsWith(cols, "672")])[2:5], NA, sort(cols[endsWith(cols, "672")])[6])),
      caption = "Eri korkeuksissa tehdyt mittaukset: Mitä muuttujia löytyy millekin korkeudelle?") %>%
  kable_styling()

```